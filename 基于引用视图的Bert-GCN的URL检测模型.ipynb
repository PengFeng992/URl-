{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AXD.PC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import  BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Bert模型和tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISCX = pd.read_csv('./ISCX-URL2016.csv')\n",
    "# 准备数据\n",
    "# 假设urls和labels分别为URL列表和对应的标签列表\n",
    "urls = ISCX['URL'].values\n",
    "labels = [0 if i=='no'  else 1 for i in ISCX['Target'].values]  # 0代表正常，1代表恶意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(url):\n",
    "    input_ids = tokenizer.encode(url, add_special_tokens=True, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    features = torch.mean(last_hidden_states, dim=1).squeeze().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "# 获取URL的特征\n",
    "urls = [extract_features(i) for i in urls[:20]]\n",
    "labels = labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成trainmask和valmask\n",
    "train_mask = np.random.choice([True, False], num_nodes, p=[0.8, 0.2])\n",
    "val_mask = ~train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[20, 768], edge_index=[2, 20], y=[20], train_mask=[20], test_mask=[20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "edges = []\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    for j in range(i+1, num_nodes):\n",
    "        if random.random() < 0.05:  # randomly generate edges with probability 0.1\n",
    "            edges.append([i, j])\n",
    "            edges.append([j, i])\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "data = Data(x=torch.tensor(np.array(urls),dtype=torch.float32),edge_index=edge_index,y=torch.tensor(labels,dtype=torch.long))\n",
    "\n",
    "data.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "data.test_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN_BERT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN_BERT, self).__init__()\n",
    "        self.feature_reduction = nn.Linear(input_dim, 64)\n",
    "        self.conv1 = GCNConv(64, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "        self.out0 = nn.Linear(output_dim, 32)\n",
    "        self.out1 = nn.Linear(output_dim, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.feature_reduction(x)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(self.out0(x))\n",
    "        x = self.out1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建GCN模型\n",
    "model = GCN_BERT(input_dim=768, hidden_dim=128, output_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_BERT(\n",
       "  (feature_reduction): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (conv1): GCNConv(64, 128)\n",
       "  (conv2): GCNConv(128, 32)\n",
       "  (out0): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (out1): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mertrics import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Recall: 0.5\n",
      "Precision: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Confusion Matrix:\n",
      " [[ 0  0]\n",
      " [10 10]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.67        20\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.50      0.25      0.33        20\n",
      "weighted avg       1.00      0.50      0.67        20\n",
      "\n",
      "AUC: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AXD.PC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\AXD.PC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\AXD.PC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\AXD.PC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 在测试集上评估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x, data.edge_index)\n",
    "    pred = pred.argmax(dim=1)\n",
    "    calculate_metrics(pred, data.y, data.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
